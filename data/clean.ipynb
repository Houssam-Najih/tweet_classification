{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e20553ed",
   "metadata": {},
   "source": [
    "# Pipeline de nettoyage de tweets pour LLM\n",
    "\n",
    "Ce notebook présente un script complet de nettoyage de tweets.\n",
    "\n",
    "Objectifs :\n",
    "- Charger un fichier CSV de tweets (`free_tweet_export.csv`)\n",
    "- Nettoyer le texte pour un usage NLP / LLM (suppression d'URLs, PII, normalisation…)\n",
    "- Extraire les hashtags et détecter les retweets\n",
    "- Supprimer les doublons et filtrer certains comptes\n",
    "- Exporter un CSV propre (`free_tweet_export_cleaned.csv`) et afficher quelques statistiques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f7f246",
   "metadata": {},
   "source": [
    "## Imports et définitions globales\n",
    "\n",
    "On importe les bibliothèques nécessaires et on définit quelques **expressions régulières** pour :\n",
    "- détecter les URLs\n",
    "- reconnaître les retweets (`RT @...`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ec9aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, html, io, base64, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "URL_PAT     = re.compile(r'https?://\\S+|www\\.\\S+', flags=re.IGNORECASE)\n",
    "RT_PAT      = re.compile(r'^rt\\s@', flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba46506",
   "metadata": {},
   "source": [
    "## Normalisation des sauts de ligne\n",
    "### Fonction `_normalize_escaped_newlines`\n",
    "\n",
    "Dans les CSV, les sauts de ligne peuvent parfois être stockés comme texte littéral `\\\\n`, `\\\\r`, `\\\\t`.\n",
    "\n",
    "Cette fonction :\n",
    "- remplace `\\\\n` par un vrai saut de ligne `\\n`\n",
    "- remplace `\\\\r` par `\\r`\n",
    "- remplace `\\\\t` par `\\t`\n",
    "\n",
    "Cela stabilise l'extraction des hashtags et le nettoyage du texte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d2bf182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_escaped_newlines(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "    return s.replace(\"\\\\r\", \"\\r\").replace(\"\\\\t\", \"\\t\").replace(\"\\\\n\", \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e7f461",
   "metadata": {},
   "source": [
    "## Extraction des hashtags\n",
    "### Fonction `extract_hashtags`\n",
    "\n",
    "Cette fonction :\n",
    "- reçoit un texte brut\n",
    "- normalise les `\\\\n`, `\\\\t`, `\\\\r`\n",
    "- extrait tous les hashtags avec une regex (`#[^\\s#]+`)\n",
    "- retourne une liste de hashtags (ex: `[\"#free\", \"#internet\"]`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d4eccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hashtags(s: str):\n",
    "    if not isinstance(s, str):\n",
    "        return []\n",
    "    text_norm = _normalize_escaped_newlines(s)\n",
    "    return re.findall(r'#[^\\s#]+', text_norm, flags=re.UNICODE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b03027",
   "metadata": {},
   "source": [
    "## Nettoyage du texte pour LLM\n",
    "### Fonction `clean_llm_text`\n",
    "\n",
    "Cette fonction applique un **nettoyage léger** du texte pour LLM :\n",
    "\n",
    "1. Normalisation des `\\\\n`, `\\\\t`, etc.\n",
    "2. Décodage des entités HTML (`&amp;` → `&`, etc.)\n",
    "3. Remplacement :\n",
    "   - des URLs par `<URL>`\n",
    "4. Aplatissement du texte :\n",
    "   - suppression des sauts de ligne → espace\n",
    "   - nettoyage des espaces en double\n",
    "5. Suppression finale des marqueurs `<URL>`\n",
    "6. Filet de sécurité : si des hashtags ont disparu après nettoyage, on les ré-append à la fin\n",
    "7. Passage du texte en minuscules (via `casefold`, plus robuste que `lower`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae79cccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_llm_text(raw: str) -> str:\n",
    "    if not isinstance(raw, str):\n",
    "        return raw\n",
    "\n",
    "    # 1) Normalisation des séquences \\n, \\r, \\t littérales\n",
    "    cleaned = _normalize_escaped_newlines(raw)\n",
    "\n",
    "    # 2) Décodage HTML\n",
    "    cleaned = html.unescape(cleaned)\n",
    "\n",
    "    # 3) Masquage PII + URLs\n",
    "    cleaned = URL_PAT.sub('<URL>', cleaned)\n",
    "\n",
    "    # 4) Normalisation des espaces / sauts de ligne\n",
    "    cleaned = re.sub(r'[ \\t]+', ' ', cleaned)\n",
    "    cleaned = re.sub(r'\\n+', ' ', cleaned).strip()\n",
    "\n",
    "    # 5) Suppression du placeholder <URL> + re-nettoyage des espaces\n",
    "    cleaned = re.sub(r'\\s*<URL>\\s*', ' ', cleaned)\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
    "\n",
    "    # 6) Vérification : on réappend les hashtags éventuellement perdus\n",
    "    raw_tags     = extract_hashtags(raw)\n",
    "    cleaned_tags = extract_hashtags(cleaned)\n",
    "    missing = [t for t in raw_tags if t not in cleaned_tags]\n",
    "    if missing:\n",
    "        cleaned += (' ' if not cleaned.endswith(' ') else '') + ' '.join(missing)\n",
    "\n",
    "    # 7) Minuscule Unicode-safe\n",
    "    return cleaned.casefold()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d2e0c8",
   "metadata": {},
   "source": [
    "## Lecture robuste du CSV\n",
    "### Fonction `read_csv_robust`\n",
    "\n",
    "Cette fonction lit un fichier CSV en essayant deux encodages :\n",
    "- d'abord `utf-8`\n",
    "- puis `utf-8-sig` (souvent généré par Excel)\n",
    "\n",
    "Elle utilise `sep=None` et `engine=\"python\"` pour laisser pandas détecter le séparateur, et ignore les lignes problématiques (`on_bad_lines=\"skip\"`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1dd55a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_robust(path: Path) -> pd.DataFrame:\n",
    "    try:\n",
    "        return pd.read_csv(path, sep=None, engine=\"python\", encoding=\"utf-8\", on_bad_lines=\"skip\")\n",
    "    except Exception:\n",
    "        return pd.read_csv(path, sep=None, engine=\"python\", encoding=\"utf-8-sig\", on_bad_lines=\"skip\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
